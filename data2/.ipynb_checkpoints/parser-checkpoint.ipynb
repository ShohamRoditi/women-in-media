{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code we are using YAP model (developed by ONLP Lab)\n",
    "https://github.com/OnlpLab/yap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun = ['NN', 'NNG', 'NNGT', 'NNP', 'NNT']\n",
    "verb = ['RB', 'RBR', 'VB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender(st):\n",
    "    gender = re.split(\"gen=\", st)\n",
    "    try:\n",
    "        if len(gender)>1:\n",
    "            return str(gender[1][0])\n",
    "        else:\n",
    "            return\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gender(df):\n",
    "    gender = 'M'\n",
    "    for i in range(len(df)):\n",
    "#         if df.loc[i,4] in noun and df.loc[i,'gender']=='F':\n",
    "#             gender = 'F'\n",
    "        if df.loc[i,4] in verb and df.loc[i,'gender']=='F':\n",
    "            return 'F'\n",
    "    return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = []\n",
    "filepath = 'bag_of_words.txt'\n",
    "with open(filepath) as fp:\n",
    "    line = fp.readline()\n",
    "    bag_of_words.append(line.strip())\n",
    "    cnt = 1\n",
    "    while line:\n",
    "        line = fp.readline()\n",
    "        bag_of_words.append(line.strip())\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in bag_of_words:\n",
    "    word.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['בעל',\n",
       " 'חבר',\n",
       " 'ילדים',\n",
       " 'להתחתן',\n",
       " 'ילד',\n",
       " 'הריון',\n",
       " 'לידה',\n",
       " 'משקל',\n",
       " 'דיאטה',\n",
       " 'קלוריות',\n",
       " 'אחות',\n",
       " 'אחותו',\n",
       " 'הבת',\n",
       " 'ילדה',\n",
       " 'בתו',\n",
       " 'בתה',\n",
       " 'אמהות',\n",
       " 'גוף',\n",
       " 'זוגיות',\n",
       " 'אהבה',\n",
       " 'דייט',\n",
       " 'תינוק',\n",
       " 'תינוקת',\n",
       " 'דייטים',\n",
       " 'אמא',\n",
       " 'פרידה',\n",
       " 'אימהות',\n",
       " 'היריון',\n",
       " 'אשת',\n",
       " 'גבר',\n",
       " 'אשתו',\n",
       " 'נפרדה',\n",
       " 'התחתנה',\n",
       " 'התגרשה',\n",
       " 'נישואין',\n",
       " 'נישואים',\n",
       " 'גירושים',\n",
       " 'גירושין',\n",
       " 'רווקות',\n",
       " 'מניקה',\n",
       " 'רווקה']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.remove(\"\")\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(list_of_words):\n",
    "    words_found = []\n",
    "    for word in list_of_words:\n",
    "        if word in bag_of_words:\n",
    "            words_found.append(word)\n",
    "    return words_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subject_and_words(r):\n",
    "    result = r.content\n",
    "    text = result.decode('utf-8')\n",
    "    d = json.loads(text)\n",
    "    txt = d['md_lattice']\n",
    "    tokens = re.split(\"\\t\", txt)\n",
    "    df = []\n",
    "    line = []\n",
    "\n",
    "    #creating dataframe from string\n",
    "    for t in tokens:\n",
    "        if '\\n' in t:\n",
    "            line.append(re.split(\"\\n\", t)[0])\n",
    "            df.append(line)\n",
    "            line = [] \n",
    "            line.append(re.split(\"\\n\", t)[1])\n",
    "        else:\n",
    "            line.append(t)\n",
    "    df = pd.DataFrame(df)\n",
    "#     df = df.drop([0,1,3,5], axis=1)\n",
    "    df = df.rename(columns={6: \"gender\"})\n",
    "    #finding gender\n",
    "    df['gender'] = df['gender'].apply(gender)\n",
    "    gender_subject = find_gender(df)\n",
    "\n",
    "    #finding the words from bag of words\n",
    "    bad_words = find_words(df[2])\n",
    "    \n",
    "    return gender_subject, bad_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../data1/data1.json', 'r') as myfile:\n",
    "    data = myfile.read()\n",
    "    posts = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "posts = posts['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Mako',\n",
       " 'header': '\"זה היה מופע פורנו, הופעה במועדון חשפנות\"',\n",
       " 'sub_header': \"מתקפה חריפה ביותר נגד ג'יי לו ואיומים בחרם\",\n",
       " 'img': 'https://img.mako.co.il/2020/02/26/jloooo_i.jpg'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Mako',\n",
       " 'header': '\"אני מופתע ועצוב לגלות שנספרסו מעבידה ילדים\"',\n",
       " 'sub_header': \"הפרזנטור ג'ורג קלוני נאלץ להגיב לתחקיר חדש\",\n",
       " 'img': 'https://img.mako.co.il/2020/02/26/GettyImages-1130400201_i.jpg'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmmm = posts[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP (Using YAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('M', [])\n",
      "('M', [])\n",
      "('M', [])\n",
      "('M', [])\n",
      "('M', [])\n",
      "('F', [])\n",
      "('M', [])\n"
     ]
    }
   ],
   "source": [
    "URL = \"http://localhost:8000/yap/heb/joint\"\n",
    "for post in posts:\n",
    "    try:\n",
    "        post_data2 = {\n",
    "            \"source\": post[\"source\"],\n",
    "            \"header\": post[\"header\"].strip(),\n",
    "            \"sub_header\": post[\"sub_header\"].strip(),\n",
    "            \"img\": post[\"img\"]\n",
    "        }\n",
    "\n",
    "        post_content = post['header']+\"  \"   \n",
    "        PARAMS = {\"text\": post_content}\n",
    "        r = requests.get(url = URL, json = PARAMS) \n",
    "        res_title = find_subject_and_words(r)\n",
    "        print(res_title)\n",
    "        post_content = post['sub_header']+\"  \"   \n",
    "        PARAMS = {\"text\": post_content}\n",
    "        r = requests.get(url = URL, json = PARAMS) \n",
    "        res_sub_title = find_subject_and_words(r)\n",
    "        if res_title[0] == 'M':\n",
    "            if res_sub_title[0] == 'M':\n",
    "                post_data2[\"gender\"] = \"M\"\n",
    "                post_data2[\"flag\"] = '0'\n",
    "            else:\n",
    "                post_data2[\"gender\"] = \"F\"\n",
    "                post_data2[\"words\"] = res_sub_title[1]\n",
    "                if len(res_sub_title[1])>0:\n",
    "                    post_data2[\"flag\"] = '1'\n",
    "                else:\n",
    "                    post_data2[\"flag\"] = '0'\n",
    "        else:\n",
    "            post_data2[\"gender\"] = \"F\"\n",
    "            if res_sub_title[0] == 'M':\n",
    "                post_data2[\"words\"] = res_title[1]\n",
    "                if len(res_title[1])>0:\n",
    "                    post_data2[\"flag\"] = '1'\n",
    "                else:\n",
    "                    post_data2[\"flag\"] = '0'\n",
    "            else:\n",
    "                post_data2[\"words\"] = res_title[1]+res_sub_title[1]\n",
    "                if len(res_title[1])+len(res_sub_title[1])>0:\n",
    "                    post_data2[\"flag\"] = '1'\n",
    "                else:\n",
    "                    post_data2[\"flag\"] = '0'\n",
    "        data2.append(post_data2)          \n",
    "    except:\n",
    "        continue\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {\"data\":data2}\n",
    "app_json = json.dumps(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data2.json\", \"a\")\n",
    "f.write(str(app_json))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions = {\n",
    "#         \"CC\": \"Coordinating conjunction\",\n",
    "#         \"CD\": \"Cardinal number\",\n",
    "#         \"EX\": \"Determiner\",\n",
    "#         \"FW\": \"Foreign word\",\n",
    "#         \"IN\": \"Preposition\",\n",
    "#         \"JJ\": \"Adjective\",\n",
    "#         \"VP\": \"Verb\",\n",
    "\n",
    "#         \"JJR\": \"Adjective\",\n",
    "#         \"JJS\": \"Adjective\",\n",
    "#         \"LS\": \"List\",\n",
    "#         \"MD\": \"Modal\",\n",
    "\n",
    "#         \"NN\": \"Noun\",\n",
    "#         \"NNS\": \"Noun\",\n",
    "#         \"PP\": \"Preposition\",\n",
    "#         \"NNP\": \"Noun\",\n",
    "#         \"NNPS\": \"Pre determiner\",\n",
    "#         \"PDT\": \"Verb\",\n",
    "#         \"TO\": \"to\",\n",
    "#         \"POS\": \"Possessive ending\",\n",
    "#         \"PRP\": \"Personal pronoun\",\n",
    "#         \"PRP$\": \"Personal pronouns\",\n",
    "#         \"RB\": \"Adverb\",\n",
    "#         \"RBR\": \"Adverb\",\n",
    "#         \"RP\": \"Particle\",\n",
    "#         \"S\": \"Simple declarative\",\n",
    "#         \"SBAR\": \"Clause introduced\",\n",
    "#         \"SBARQ\": \"null\",\n",
    "#         \"SINV\": \"null\",\n",
    "#         \"DT\": \"determiner\",\n",
    "#         \"SQ\": \"null\",\n",
    "#         \"SYM\": \"Symbol\",\n",
    "#         \"VB\": \"Verb\",\n",
    "#         \"UH\": \"interjection\",\n",
    "#         \"VBD\": \"Verb\",\n",
    "#         \"VBG\": \"Verb\",\n",
    "#         \"VBN\": \"Verb\",\n",
    "#         \"VBP\": \"Verb\",\n",
    "#         \"VBZ\": \"Verb\",\n",
    "#         \"WP\": \"Pronoun\",\n",
    "#         \"WRB\": \"Adverb\",\n",
    "#         \":\": \"none\",\n",
    "#         \"\": \"none\",\n",
    "#         \"WDT\": \"Wh-determiner\"\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
