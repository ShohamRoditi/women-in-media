{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code we are using YAP model (developed by ONLP Lab)\n",
    "https://github.com/OnlpLab/yap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun = ['NN', 'NNG', 'NNGT', 'NNP', 'NNT']\n",
    "verb = ['RB', 'RBR', 'VB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender(st):\n",
    "    gender = re.split(\"gen=\", st)\n",
    "    try:\n",
    "        if len(gender)>1:\n",
    "            return str(gender[1][0])\n",
    "        else:\n",
    "            return\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gender(df):\n",
    "    gender = 'M'\n",
    "    for i in range(len(df)):\n",
    "#         if df.loc[i,4] in noun and df.loc[i,'gender']=='F':\n",
    "#             gender = 'F'\n",
    "        if df.loc[i,4] in verb and df.loc[i,'gender']=='F':\n",
    "            return 'F'\n",
    "    return gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = []\n",
    "filepath = 'bag_of_words.txt'\n",
    "with open(filepath) as fp:\n",
    "    line = fp.readline()\n",
    "    bag_of_words.append(line.strip())\n",
    "    cnt = 1\n",
    "    while line:\n",
    "        line = fp.readline()\n",
    "        bag_of_words.append(line.strip())\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in bag_of_words:\n",
    "    word.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(list_of_words):\n",
    "    words_found = []\n",
    "    for word in list_of_words:\n",
    "        if word in bag_of_words:\n",
    "            words_found.append(word)\n",
    "    return words_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subject_and_words(r):\n",
    "    result = r.content\n",
    "    text = result.decode('utf-8')\n",
    "    d = json.loads(text)\n",
    "    txt = d['md_lattice']\n",
    "    tokens = re.split(\"\\t\", txt)\n",
    "    df = []\n",
    "    line = []\n",
    "\n",
    "    #creating dataframe from string\n",
    "    for t in tokens:\n",
    "        if '\\n' in t:\n",
    "            line.append(re.split(\"\\n\", t)[0])\n",
    "            df.append(line)\n",
    "            line = [] \n",
    "            line.append(re.split(\"\\n\", t)[1])\n",
    "        else:\n",
    "            line.append(t)\n",
    "    df = pd.DataFrame(df)\n",
    "#     df = df.drop([0,1,3,5], axis=1)\n",
    "    df = df.rename(columns={6: \"gender\"})\n",
    "    #finding gender\n",
    "    df['gender'] = df['gender'].apply(gender)\n",
    "    gender_subject = find_gender(df)\n",
    "\n",
    "    #finding the words from bag of words\n",
    "    bad_words = find_words(df[2])\n",
    "    \n",
    "    return gender_subject, bad_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../data1/data1.json', 'r') as myfile:\n",
    "    data = myfile.read()\n",
    "    posts = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "posts = posts['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP (Using YAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"http://localhost:8000/yap/heb/joint\"\n",
    "for post in posts:\n",
    "    try:\n",
    "        post_data2 = {\n",
    "            \"source\": post[\"source\"],\n",
    "            \"header\": post[\"header\"].strip(),\n",
    "            \"sub_header\": post[\"sub_header\"].strip(),\n",
    "            \"img\": post[\"img\"]\n",
    "        }\n",
    "\n",
    "        post_content = post['header']+\"  \"   \n",
    "        PARAMS = {\"text\": post_content}\n",
    "        r = requests.get(url = URL, json = PARAMS) \n",
    "        res_title = find_subject_and_words(r)\n",
    "        post_content = post['sub_header']+\"  \"   \n",
    "        PARAMS = {\"text\": post_content}\n",
    "        r = requests.get(url = URL, json = PARAMS) \n",
    "        res_sub_title = find_subject_and_words(r)\n",
    "        if res_title[0] == 'M':\n",
    "            if res_sub_title[0] == 'M':\n",
    "                post_data2[\"gender\"] = \"M\"\n",
    "                post_data2[\"flag\"] = '0'\n",
    "            else:\n",
    "                post_data2[\"gender\"] = \"F\"\n",
    "                post_data2[\"words\"] = res_sub_title[1]\n",
    "                if len(res_sub_title[1])>0:\n",
    "                    post_data2[\"flag\"] = '1'\n",
    "                else:\n",
    "                    post_data2[\"flag\"] = '0'\n",
    "        else:\n",
    "            post_data2[\"gender\"] = \"F\"\n",
    "            if res_sub_title[0] == 'M':\n",
    "                post_data2[\"words\"] = res_title[1]\n",
    "                if len(res_title[1])>0:\n",
    "                    post_data2[\"flag\"] = '1'\n",
    "                else:\n",
    "                    post_data2[\"flag\"] = '0'\n",
    "            else:\n",
    "                post_data2[\"words\"] = res_title[1]+res_sub_title[1]\n",
    "                if len(res_title[1])+len(res_sub_title[1])>0:\n",
    "                    post_data2[\"flag\"] = '1'\n",
    "                else:\n",
    "                    post_data2[\"flag\"] = '0'\n",
    "        data2.append(post_data2)          \n",
    "    except:\n",
    "        continue\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {\"data\":data2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data2.json\",\"w\", encoding='utf-8') as jsonfile:\n",
    "        json.dump(data2,jsonfile,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions = {\n",
    "#         \"CC\": \"Coordinating conjunction\",\n",
    "#         \"CD\": \"Cardinal number\",\n",
    "#         \"EX\": \"Determiner\",\n",
    "#         \"FW\": \"Foreign word\",\n",
    "#         \"IN\": \"Preposition\",\n",
    "#         \"JJ\": \"Adjective\",\n",
    "#         \"VP\": \"Verb\",\n",
    "\n",
    "#         \"JJR\": \"Adjective\",\n",
    "#         \"JJS\": \"Adjective\",\n",
    "#         \"LS\": \"List\",\n",
    "#         \"MD\": \"Modal\",\n",
    "\n",
    "#         \"NN\": \"Noun\",\n",
    "#         \"NNS\": \"Noun\",\n",
    "#         \"PP\": \"Preposition\",\n",
    "#         \"NNP\": \"Noun\",\n",
    "#         \"NNPS\": \"Pre determiner\",\n",
    "#         \"PDT\": \"Verb\",\n",
    "#         \"TO\": \"to\",\n",
    "#         \"POS\": \"Possessive ending\",\n",
    "#         \"PRP\": \"Personal pronoun\",\n",
    "#         \"PRP$\": \"Personal pronouns\",\n",
    "#         \"RB\": \"Adverb\",\n",
    "#         \"RBR\": \"Adverb\",\n",
    "#         \"RP\": \"Particle\",\n",
    "#         \"S\": \"Simple declarative\",\n",
    "#         \"SBAR\": \"Clause introduced\",\n",
    "#         \"SBARQ\": \"null\",\n",
    "#         \"SINV\": \"null\",\n",
    "#         \"DT\": \"determiner\",\n",
    "#         \"SQ\": \"null\",\n",
    "#         \"SYM\": \"Symbol\",\n",
    "#         \"VB\": \"Verb\",\n",
    "#         \"UH\": \"interjection\",\n",
    "#         \"VBD\": \"Verb\",\n",
    "#         \"VBG\": \"Verb\",\n",
    "#         \"VBN\": \"Verb\",\n",
    "#         \"VBP\": \"Verb\",\n",
    "#         \"VBZ\": \"Verb\",\n",
    "#         \"WP\": \"Pronoun\",\n",
    "#         \"WRB\": \"Adverb\",\n",
    "#         \":\": \"none\",\n",
    "#         \"\": \"none\",\n",
    "#         \"WDT\": \"Wh-determiner\"\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
